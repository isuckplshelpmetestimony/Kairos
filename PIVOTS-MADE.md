# 🔄 KAIROS CMA TOOL - PIVOTS MADE

**Document Created:** September 30, 2025  
**Context:** Architectural decisions and pivots made during Cursor AI conversation  
**Purpose:** Record the journey from complex AI agent to lean MVP

---

## 📌 EXECUTIVE SUMMARY

**What Changed:**
- From: Complex AI agent architecture (3-4 months, $2.50/report)
- To: Simple Flask wrapper (3 weeks, $0)

**How:**
- Removed unnecessary AI (5 subsystems → 0)
- Removed complex planning (agent architecture → simple API)
- Kept only validation essentials (scrapers + stats + display)
- Used free hosting (Netlify/Railway → Render + UptimeRobot)

**Result:**
- 10x faster to ship
- $0 infrastructure cost
- Validates product-market fit first
- Can add complexity later if proven valuable

---

## 🔁 PIVOT: Transition to Kairos v4 Scraping Method (Lamudi)

### Why we pivoted
- Original flow (scraper ➝ CSV ➝ API/UI) was brittle: list selectors often returned 0 cards, detail selectors drifted, and NaN/raw_data leaked to JSON causing UI errors and N/A stats.
- We needed reliability without changing UI/contract, so we adopted the Kairos v4 pattern: adapter-normalized in‑memory results, minimally hardened scraper, and stats computed from a full numeric price series.

### What changed (surgical edits)
- List pages: kept primary class selectors; always ran one attribute/URL fallback; merged candidates per page; deduped by SKU; breadth‑only mini‑crawl with `SCRAPER_MAX_PAGES` (default 10); early stop on requested count.
- Pagination fix: removed `num` shadowing when parsing `?page=` so requested count is honored.
- Detail pages: retained primaries; added one attribute/text fallback per field (price, sqm, beds, baths); added SKU‑from‑URL fallback; jitter 0.3–0.8s; timeout 15s.
- Normalization adapter: mapped to canonical fields; sanitized NaN to JSON‑safe values; removed `raw_data`; coordinates None when missing; capped response properties (now 100) while keeping full price series for stats.
- API orchestration: single‑flight lock; prefer in‑memory adapter results; compute stats from series; logs success/empty with optional pages_scanned (no PII); CSV retained for diagnostics.

### Outcomes observed
- Metro Manila condo run: site exposed 2 pages; crawler collected ~31 unique links; after fallbacks and SKU fixes, up to 31 normalized properties returned; UI unchanged; logs clean.
- Raising response cap beyond discovered links does not increase results unless the site exposes more pages; scraper scans 1..min(detected_pages, MAX_PAGES).

### Guardrails respected
- No new deps/headless/proxies/queues/routes; same‑host; no depth > 1.
- Secure inputs; PII‑free logging; small typed adapter module; CSV diagnostics preserved; API/UI contract unchanged.

### Quick runbook (dev)
- Backend: `pkill -f "python3 app.py" || true` then `cd backend && SCRAPER_MAX_PAGES=10 PORT=3000 python3 app.py`
- Frontend: `cd Kairos && npm run dev -- --port 3001`
- API test: `curl -s -X POST http://localhost:3000/api/cma -H "Content-Type: application/json" -d '{"psgc_province_code":"1376","property_type":"condo","count":50}' | jq`

---

## 🎯 ORIGINAL PROPOSAL (What We Avoided)

### **The Initial Vision**

Build a "Planning Subsystem" as the FIRST subsystem for Kairos that:

- **Technology:** Python + GLM-4.5-AIR (Chinese AI model)
- **Architecture:** 5 subsystems (Planning, Perception, Memory, Execution, Verification)
- **Approach:** AI-powered brain that reasons about data collection BEFORE scraping
- **Features:**
  - Predicts data quality before scraping
  - Creates intelligent scraping strategies
  - Applies "Claude-style critical reasoning"
  - Philippine market intelligence (monsoon adjustments, OFW remittances, etc.)
  - Confidence scoring and fallback strategies

### **Proposed Timeline**

```
Week 1-4:   Build Planning Subsystem (Python + GLM-4.5-AIR)
Week 5-8:   Build scrapers to receive planning strategies
Week 9-12:  Integrate everything together
Week 13+:   Finally ship to users

Total: 3-4 months to first demo
```

### **Proposed Costs**

- **Per Report:** $2.50 (5 GLM-4.5-AIR API calls)
- **Hosting:** $19/month (Netlify Pro for Background Functions)
- **At 100 reports/month:** $269/month

### **Proposed Complexity**

- Two languages (TypeScript frontend + Python backend)
- Five subsystems with complex interactions
- AI integration and prompt engineering
- Agent architecture with state management
- Privacy concerns (user data to Chinese AI)

---

## 🔍 CRITICAL ANALYSIS (Why It Was Wrong)

### **Fatal Flaw #1: Building Brain Before Body**

**The Problem:**
Creating a planning system for scrapers that don't exist yet.

**Like:**
- Designing traffic control before building roads
- Installing smart home system before building house
- Planning telescope observations before building telescope

**Why It Fails:**
Can't intelligently plan data collection without seeing what real data looks like.

---

### **Fatal Flaw #2: Wrong Build Order**

**Proposed Order:**
```
1. Planning Subsystem (AI reasoning)
2. Build scrapers (to receive strategies)
3. Collect data
4. Generate reports
```

**Correct Order:**
```
1. Build scrapers (get real data)
2. Generate reports (prove value exists)
3. Learn from users (what do they need?)
4. THEN add intelligence (if validated)
```

**Principle:** Build foundation first, optimization layer last.

---

### **Fatal Flaw #3: AI Where Logic Suffices**

**Most "subsystems" didn't need AI:**

| Subsystem | Proposed (AI) | Reality (Logic) |
|-----------|---------------|-----------------|
| **Planning** | GLM decides scraper priority | `if (location === 'NCR') use Lamudi else use Facebook` |
| **Memory** | GLM stores patterns | Supabase database tables |
| **Perception** | GLM normalizes addresses | ph-address library |
| **Execution** | GLM orchestrates | `Promise.allSettled([scraper1, scraper2])` |
| **Verification** | GLM detects outliers | `Math.abs(price - avg) > 2 * stdDev` |

**Only report narrative generation needs AI.**

**Cost comparison:**
- AI approach: $2.50 per report
- Logic approach: $0 per report

---

### **Fatal Flaw #4: Premature Optimization**

**The Lean Startup Principle:**
Build → Measure → Learn → Iterate

**What was proposed:**
Build Perfect System → Hope Users Want It

**Problems:**
- 3 months before first user feedback
- Can't pivot easily (too much invested)
- Don't know if users value "intelligence"
- Sunk cost fallacy (can't abandon after 3 months work)

---

### **Fatal Flaw #5: Hard-Coded "Intelligence"**

**Example from proposal:**
```python
if 6 <= current_month <= 10:
    velocity_multiplier *= 0.85  # Monsoon season
if current_month == 12:
    velocity_multiplier *= 1.25  # OFW remittances
```

**Problems:**
- Climate patterns shifting (not fixed June-Oct anymore)
- Market dynamics evolve (post-pandemic changes)
- No validation (where's data proving 0.85 is correct?)
- Regional differences (Cebu ≠ Manila)
- Maintenance burden (update code when market changes)

**Should be:** Data-driven from historical analysis, not assumption-driven.

---

## 💡 PIVOT #1: Remove AI Entirely (Week 1)

### **The Realization**

"Why spend 3 months building AI reasoning before validating anyone wants CMA reports?"

### **The Decision**

**Remove GLM-4.5-AIR completely from MVP.**

Add as "complementary feature" only AFTER:
- Users prove they want basic reports
- Users request AI-written narratives
- Have revenue to justify AI costs

### **Impact**

- ✅ Saved 4+ weeks of AI integration
- ✅ Saved $2.50 per report
- ✅ No privacy concerns
- ✅ Simpler codebase
- ✅ Faster to ship

### **What Was Kept**

Simple calculations:
- Average price: `sum(prices) / count`
- Median price: `sorted(prices)[middle]`
- Range: `[min, max]`
- Count: `properties.length`

No AI needed for this.

---

## 🏗️ PIVOT #2: Serverless Won't Work (Week 1)

### **The Discovery**

"Can I just use Netlify Functions instead of a VPS?"

### **The Research**

| Platform | Max Execution Time | Your Scraper Needs |
|----------|-------------------|-------------------|
| **Netlify Free** | 10 seconds | 5-10 MINUTES ❌ |
| **Netlify Pro** | 26 seconds | 5-10 MINUTES ❌ |
| **Vercel Free** | 10 seconds | 5-10 MINUTES ❌ |
| **Vercel Pro** | 60 seconds | 5-10 MINUTES ❌ |
| **Render Free** | No limit | 5-10 MINUTES ✅ |

### **The Reality**

Serverless platforms CANNOT run 5-10 minute web scrapers. This is a physics problem, not a configuration problem.

### **Impact**

- ❌ Cannot use Netlify Functions
- ❌ Cannot use Vercel Serverless
- ✅ Need actual server (VPS or long-running service)

---

## 🎯 PIVOT #3: Render + UptimeRobot = Free (Week 1)

### **The Problem**

Render free tier spins down after 15 minutes of inactivity.

First request after sleep:
- Wake up: 1 minute
- Scrape: 5-10 minutes
- **Total: 6-11 minutes** (terrible UX)

### **Your Solution**

"I can use UptimeRobot to ping every 5 minutes. I've done this before on another project."

### **Why This Works**

**UptimeRobot (free):**
- Pings `/health` endpoint every 5 minutes
- Keeps Render server awake
- Prevents spin-down delay

**Result:** Effectively unlimited uptime for $0.

### **Impact**

- ✅ Render free tier usable
- ✅ No spin-down delays
- ✅ Total cost: $0

**This was brilliant.** You already had proven solution.

---

## 🔄 PIVOT #4: One Platform, Not Two (Week 2)

### **Initial Recommendation**

- Frontend: Netlify (already working)
- Backend: Render (new)
- Total: 2 platforms

**Reasoning:** Don't touch what's working (risk-averse).

### **Your Question**

"Why maintain TWO platforms? Can't I just use Render for everything?"

### **Your Logic**

- Already adding Render for backend
- Render can host static sites too
- One platform = simpler
- One config file (render.yaml)
- One dashboard
- One deployment

### **The Decision**

**You were right.** One platform IS simpler.

Move everything to Render:
- Static Site (frontend)
- Web Service (backend)
- Single render.yaml deploys both

### **Impact**

- ✅ One platform to learn
- ✅ One configuration file
- ✅ One deployment process
- ✅ Simpler mental model
- ✅ Easier to manage

**Lesson:** I was optimizing for risk-aversion. You were optimizing for simplicity. For MVP, simplicity wins.

---

## 🐍 PIVOT #5: It's Python, Not Node.js (Week 2)

### **The Discovery**

You shared: https://github.com/njolnir/Lamudi_Scraper

### **The Shock**

**I had assumed:** Node.js scraper (because frontend is TypeScript)
**Reality:** Python scraper (BeautifulSoup, pandas)

### **Impact**

**All my code examples were wrong language.**

Had to revise entire implementation:
- ❌ Express server → ✅ Flask server
- ❌ npm packages → ✅ pip packages
- ❌ JavaScript scraper integration → ✅ Python function calls
- ❌ Node.js deployment → ✅ Python runtime

### **New Stack**

```
Frontend: React/TypeScript (unchanged)
Backend: Python/Flask (changed from Node.js)
Scraper: Python (BeautifulSoup)
Platform: Render (supports both)
```

### **Lesson**

Always verify tech stack assumptions before proposing architecture.

---

## 📊 OLD VS NEW COMPARISON

### **ORIGINAL APPROACH (Avoided)**

```
Technology:
├─ Python backend
├─ GLM-4.5-AIR (Chinese AI)
├─ 5 subsystems (agent architecture)
├─ Philippine market intelligence (hard-coded)
└─ Complex state management

Timeline:
├─ Week 1-4:   Planning Subsystem
├─ Week 5-8:   Build scrapers
├─ Week 9-12:  Integration
└─ Week 13+:   Ship to users

Cost:
├─ Per report: $2.50 (5 AI calls)
├─ Hosting: $19/month (Netlify Pro)
└─ At 100 reports: $269/month

Complexity:
├─ Two languages (TypeScript + Python)
├─ AI integration (prompts, error handling)
├─ Agent architecture (subsystem coordination)
├─ Privacy concerns (Chinese AI)
└─ Hard to maintain

Risk:
├─ Build for 3 months before user feedback
├─ Might be building wrong thing
├─ High sunk cost (can't abandon easily)
└─ Expensive to run at scale
```

---

### **NEW LEAN APPROACH (What We Built)**

```
Technology:
├─ Python/Flask backend (minimal)
├─ Open-source scraper (existing)
├─ Simple REST API (one endpoint)
├─ Basic math (average, median, range)
└─ No AI (just calculations)

Timeline:
├─ Week 1:  Scraper + Flask wrapper
├─ Week 2:  Deploy + Connect frontend
└─ Week 3:  Polish + Demo prep

Cost:
├─ Per report: $0
├─ Hosting: $0 (Render free tier)
├─ Monitoring: $0 (UptimeRobot free)
└─ Total: $0

Complexity:
├─ 7 files total
├─ ~100 lines of new code
├─ One platform (Render)
├─ Standard tech (Flask + React)
└─ Easy to understand

Risk:
├─ Ship in 3 weeks (fast feedback)
├─ Validates concept quickly
├─ Low sunk cost (can pivot easily)
└─ Free to run
```

---

## 🎓 KEY INSIGHTS

### **Insight #1: AI ≠ Intelligence**

**Misconception:** "AI makes systems intelligent"

**Reality:** Most intelligence is just logic:
- Planning = Lookup tables
- Verification = Math formulas
- Memory = Database queries
- Perception = Library calls

**AI only valuable for:** Natural language generation, complex pattern recognition

**When to add AI:** After validating users want it and will pay for it.

---

### **Insight #2: Foundation Before Optimization**

**Wrong order:**
```
Optimization (Planning AI) → Foundation (Scrapers) → Product
```

**Right order:**
```
Foundation (Scrapers) → Product → Optimization (if needed)
```

**Why:** Can't optimize what doesn't exist. Build it first, measure it, THEN optimize bottlenecks.

---

### **Insight #3: Validate Before You Build**

**Product Development Anti-Pattern:**
```
Assume what users want
  ↓
Build sophisticated solution
  ↓
Hope users want it
  ↓
Discover they wanted something else
  ↓
Sunk cost fallacy
```

**Lean Startup Pattern:**
```
Build minimum viable version
  ↓
Ship to real users
  ↓
Learn what they actually want
  ↓
Build THAT
  ↓
Avoid waste
```

---

### **Insight #4: Simplicity Beats Sophistication**

**For 3-week MVP:**
- Simple beats sophisticated
- Fast beats perfect
- Learning beats planning
- Cheap beats expensive
- Working beats elegant

**After product-market fit:**
- Then add sophistication
- Then optimize performance
- Then build for scale
- Then invest in infrastructure

---

### **Insight #5: User Was Often Right**

**Times user corrected me:**

1. **"Why not just use Render for everything?"**
   - I said: Keep Netlify + Add Render
   - User said: Just Render
   - **User was right** ✅

2. **"I have solution for Render spin-down"**
   - I was researching paid solutions
   - User said: UptimeRobot (already proven)
   - **User was right** ✅

3. **"Why not replace netlify.toml with render.yaml?"**
   - I said: Keep both during transition
   - User said: Just use one platform
   - **User was right** ✅

**Pattern:** I optimized for risk-aversion. User optimized for simplicity. For MVP, **simplicity wins**.

---

## 📋 FINAL IMPLEMENTATION PLAN

### **The Actual Steps (After All Pivots)**

1. **Test scraper locally** (15 min) - Verify it returns data
2. **Create backend folder** (10 min) - Organize code
3. **Wrap scraper in Flask** (30 min) - One endpoint
4. **Add dependencies** (2 min) - requirements.txt
5. **Test locally** (10 min) - curl the API
6. **Create render.yaml** (5 min) - Deploy config
7. **Deploy to Render** (10 min) - Git push
8. **Set up UptimeRobot** (5 min) - Keep awake
9. **Call API from frontend** (20 min) - Add function
10. **Deploy frontend** (5 min) - Git push
11. **Test end-to-end** (30 min) - Full verification

**Total time:** ~4 hours  
**Total files:** 3 new, 1 modified  
**Total code:** ~100 lines

---

## 💰 COST COMPARISON

| Item | Original | Final | Savings |
|------|----------|-------|---------|
| **AI per report** | $2.50 | $0 | $2.50 |
| **Hosting** | $19/month | $0 | $19/month |
| **Monitoring** | - | $0 | - |
| **At 100 reports** | $269/month | $0 | $269/month |
| **At 1000 reports** | $2,519/month | $0 | $2,519/month |

**Total savings over 6 months (at 100 reports/month): $1,614**

---

## ⏰ TIME COMPARISON

| Milestone | Original | Final | Time Saved |
|-----------|----------|-------|------------|
| **Backend working** | Week 4-8 | Week 1 | 3-7 weeks |
| **First deployment** | Week 9-12 | Week 2 | 7-10 weeks |
| **Demo ready** | Month 4+ | Week 3 | 2-3 months |
| **User feedback** | Month 4+ | Week 3 | 2-3 months |

**Total time saved: 2-3 months**

---

## 🎯 WHAT WE'RE ACTUALLY BUILDING

### **Product**
Kairos - Philippine Real Estate CMA Tool

### **Target**
3 companies in 3 weeks (demo deadline)

### **Tech Stack**
```
Frontend:
├─ React/TypeScript
├─ Vite build system
├─ Deployed: Render Static Site
└─ Cost: $0

Backend:
├─ Python/Flask
├─ Open-source Lamudi scraper
├─ Deployed: Render Web Service
└─ Cost: $0

Monitoring:
├─ UptimeRobot (keeps backend awake)
└─ Cost: $0

Total Infrastructure: $0/month
```

### **Features (MVP)**
✅ Enter Philippine address  
✅ Filter by property type  
✅ Scrape real Lamudi data (5-10 min)  
✅ Calculate statistics (avg, median, range)  
✅ Display results in UI  
✅ Basic error handling

### **NOT Included (Add Later)**
❌ Multiple scrapers (just Lamudi for now)  
❌ Database/report history  
❌ User accounts  
❌ AI-generated narratives  
❌ Advanced analytics  
❌ PDF export  
❌ Historical trends

**Philosophy:** Ship minimal → Learn → Add what users actually want

---

## 🔮 WHAT HAPPENS NEXT

### **If Demos Succeed (Companies Want to Buy)**

**Immediate additions:**
- User authentication (Supabase Auth)
- Save reports (Supabase Database)
- Payment processing (Stripe)
- More scrapers (Carousell, Facebook)
- PDF export

**Architecture impact:**
- Current structure supports all this
- Add new Flask endpoints
- Add new React components
- Scale Render to paid tier (~$20/month)

**Cost with revenue:**
- $20/month hosting is affordable
- Can add AI narratives ($0.50 per report via Claude)
- ROI positive if charging $10-20 per report

---

### **If Demos Fail (Companies Don't Want This)**

**Questions to answer:**
- Why didn't they want it?
- Too slow? Wrong data? Wrong features?
- Different target market?

**Time wasted:**
- Only 3 weeks
- Only $0 spent
- Only ~100 lines of code

**Pivot options:**
- Try different market segment
- Try different data source
- Try different product with same tech
- Learn and move on

**Key advantage:** Low sunk cost makes pivoting easy.

---

## 📚 LESSONS FOR FUTURE PROJECTS

### **Do:**
✅ Start with simplest possible version  
✅ Validate with real users fast  
✅ Use free tools when possible  
✅ Keep codebase lean  
✅ Question complexity  
✅ Trust your instincts  
✅ One platform when possible

### **Don't:**
❌ Build sophisticated features before validation  
❌ Add AI when logic suffices  
❌ Over-engineer for imaginary scale  
❌ Plan extensively without executing  
❌ Ignore simpler alternatives  
❌ Maintain multiple platforms unnecessarily  
❌ Build for months without user feedback

### **Remember:**
> "Perfect is the enemy of good"  
> "Make it work, make it right, make it fast" (in that order)  
> "Build the telescope before planning which stars to observe"

---

## 🚀 NEXT ACTION

**Start here:**
```bash
git clone https://github.com/njolnir/Lamudi_Scraper.git
cd Lamudi_Scraper
pip install -r requirements.txt
python lamudi_scraper.py
```

**If scraper works:** Follow 11-step implementation plan  
**If scraper broken:** Debug it together first

**3 weeks from now:** Demo to 3 companies with working product

---

## 🔄 PIVOT #6: Component Data Sources - Scraped vs Projected (October 2025)

### **The Problem**

After integrating ML projections CSV into the dashboard, **all components appeared static** when searching different locations within the same province. Users perceived the entire dashboard as unchanging, even though ML projections were updating correctly in the background.

### **The Discovery**

**Root Cause:** Multiple data sources were mixed together in components, creating confusion:
- Scraped data (real Lamudi listings) naturally shows the same results for locations within the same province
- ML projections were changing dynamically, but users couldn't see the difference
- Components showed a mix of both, making it unclear what was real vs projected

### **The Decision**

**Isolate data sources at the component level:**

#### **Scraped Data Only (Real Lamudi Results):**
1. ✅ **Property Report** - Real property listings from Lamudi
2. ✅ **CMA Summary** (Average, Median, Range) - Calculated from scraped properties
3. ✅ **Locations/Neighborhoods** - Real neighborhood data from listings

#### **ML Projections Only (CSV-Driven):**
1. ✅ **Avg Days on Market** (MetricCard) - From `projection.avg_dom`
2. ✅ **Market Activity** (Active/Pending/Closed) - From `projection.active_count`, `pending_count`, `closed_count`
3. ✅ **Avg Sold Price** (CMASummaryTable) - From `projection.avg_sold_price`
4. ✅ **Median Sold Price** (CMASummaryTable) - From `projection.median_sold_price`
5. ✅ **Avg Days on Market** (LocationsTable) - From `projection.avg_dom`
6. ✅ **Historical Trends** - From `projection.trend_6m` (6-month price trajectory)

### **Why This Works**

**Clear Data Boundaries:**
- Users understand which metrics are from real listings (Property Report, CMA)
- Which metrics are market intelligence projections (DOM, Market Activity, Historical Trends)
- No confusion about data sources

**Dynamic Updates:**
- When searching "Metro Manila" → Shows Metro Manila projections
- When searching "Cebu" → Shows Cebu projections
- Each of the 18 locations has unique ML projections

**Professional Transparency:**
- Projected data labeled as "Market Intelligence (X data points)"
- Mock data labels removed from real scraped components
- Users trust what they see because sources are clear

### **Implementation Changes**

**CSV Loading & State Management:**
```typescript
// App.tsx
const [projectionsMap, setProjectionsMap] = useState<Map<string, ProjectionData>>(new Map());
const [currentProjection, setCurrentProjection] = useState<ProjectionData | null>(null);

// Load CSV on mount
useEffect(() => {
  loadProjections().then(setProjectionsMap);
}, []);

// Update projection when address changes
useEffect(() => {
  if (selectedAddress?.location?.psgc_province_code) {
    const psgcCode = selectedAddress.location.psgc_province_code.toString();
    let projection = projectionsMap.get(psgcCode);
    
    // Fallback to name-based matching if PSGC fails
    if (!projection && selectedAddress.full_address) {
      projection = findProjectionByName(projectionsMap, selectedAddress.full_address);
    }
    
    setCurrentProjection(projection || null);
  }
}, [selectedAddress, projectionsMap]);
```

**Component Prop Drilling:**
```typescript
// Pass projections only to components that need them
<MetricCard 
  title="Avg Days on Market" 
  value={currentProjection ? `${currentProjection.avg_dom}` : "28"} 
/>

<MarketActivity cma={cma} projection={currentProjection} />
<HistoricalTrends cma={cma} projection={currentProjection} />
<CMASummaryTable cma={cma} projection={currentProjection} />
<LocationsTable cma={cma} projection={currentProjection} />
```

**Component Updates:**
```typescript
// MarketActivity.tsx - Use projections directly
const activeCount = projection ? projection.active_count : Math.floor(totalCount * 0.68);
const pendingCount = projection ? projection.pending_count : Math.floor(totalCount * 0.25);
const closedCount = projection ? projection.closed_count : Math.floor(totalCount * 0.07);

// HistoricalTrends.tsx - Use 6-month trend data
const dataPoints = projection?.trend_6m || [450, 465, 470, 472, 478, 485];
```

### **Impact**

**Before Pivot:**
- ❌ Users confused about static vs dynamic data
- ❌ Mock data labels everywhere ("Mock data placeholder")
- ❌ Mixed data sources in components
- ❌ Unclear what's real vs projected

**After Pivot:**
- ✅ Clear separation: Real listings vs Market intelligence
- ✅ Dynamic projections for 18 Philippine locations
- ✅ Professional labeling ("Market Intelligence (X data points)")
- ✅ Users trust the dashboard because sources are transparent

### **Technical Details**

**CSV Structure:**
```csv
psgc_code,area_name,avg_sold_price,median_sold_price,avg_dom,active_count,pending_count,closed_count,trend_6m,confidence,sample_size
1376,Metro Manila,16631289,15325748,38,50,18,5,"16225648,16808081,16923067,17363097,17634040,16631289",high,4148
```

**Projection Lookup Logic:**
1. **PSGC Code Match** - Exact match on province code
2. **Name-Based Fallback** - Case-insensitive partial matching
3. **Graceful Degradation** - Falls back to reasonable defaults if no projection found

**Coverage:**
- 18 Philippine locations with ML projections
- Realistic market fluctuations (seasonal trends, volatility)
- Confidence levels: High (4000+ samples) to Low (10-50 samples)

### **UI/UX Improvements**

**Removed Distracting Elements:**
- ❌ Removed green percentage texts ("+12% from last month", "N/A")
- ❌ Removed "View" links from individual property listings
- ❌ Removed red "Mock data placeholder" labels from scraped components
- ✅ Kept only Historical Trends visualization for trend display

**Label Updates:**
- Changed red text → gray text for softer appearance
- "Mock data placeholder" → "Market Intelligence (X data points)"
- Maintained transparency about projection sources

### **Guardrails Respected**

✅ **Minimal Technical Debt** - Just CSV parsing, no new libraries  
✅ **No Backend Changes** - Frontend-only integration  
✅ **Type Safety** - Full TypeScript interfaces (`ProjectionData`)  
✅ **Scalable** - Easy to update CSV monthly with new ML runs  
✅ **Transparent** - Clear labeling of data sources  
✅ **Simple** - ~100 lines of new code, 1 new file

### **Lessons Learned**

1. **Data Source Clarity > Feature Richness** - Users need to trust what they see
2. **Component Isolation** - Each component should have a clear, singular data source
3. **Transparent Labeling** - Always show users where data comes from
4. **Graceful Fallbacks** - Name-based matching improves UX when PSGC codes mismatch
5. **CSV is Sufficient** - No need for database/API for static projections

### **Future Enhancements**

**When ML model improves:**
- Just replace `projections.csv` with updated file
- No code changes needed
- Projections update automatically

**When adding more locations:**
- Add rows to CSV
- Lookup logic already handles new entries
- No component changes required

**When integrating real MLS data:**
- Replace ML projections with actual temporal data
- Same component structure works
- Just swap data source

---

## 📝 DOCUMENT METADATA

**Created:** September 30, 2025  
**Author:** Sean Macalintal (with AI assistance)  
**Purpose:** Record architectural pivots and decision rationale  
**Status:** Active reference document  
**Last Updated:** October 9, 2025

**Related Documents:**
- `PSGC-DATA-SEARCHING-REFERENCE.md` - Address search architecture decisions
- `KAIROS-DASHBOARD-DESIGN-SYSTEM.md` - ML Projections Integration details
- `Kairos/README.md` - Project overview
- `render.yaml` - Deployment configuration

---

**END OF DOCUMENT**
