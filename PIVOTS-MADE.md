# üîÑ KAIROS CMA TOOL - PIVOTS MADE

**Document Created:** September 30, 2025  
**Context:** Architectural decisions and pivots made during Cursor AI conversation  
**Purpose:** Record the journey from complex AI agent to lean MVP

---

## üìå EXECUTIVE SUMMARY

**What Changed:**
- From: Complex AI agent architecture (3-4 months, $2.50/report)
- To: Simple Flask wrapper (3 weeks, $0)

**How:**
- Removed unnecessary AI (5 subsystems ‚Üí 0)
- Removed complex planning (agent architecture ‚Üí simple API)
- Kept only validation essentials (scrapers + stats + display)
- Used free hosting (Netlify/Railway ‚Üí Render + UptimeRobot)

**Result:**
- 10x faster to ship
- $0 infrastructure cost
- Validates product-market fit first
- Can add complexity later if proven valuable

---

## üîÅ PIVOT: Transition to Kairos v4 Scraping Method (Lamudi)

### Why we pivoted
- Original flow (scraper ‚ûù CSV ‚ûù API/UI) was brittle: list selectors often returned 0 cards, detail selectors drifted, and NaN/raw_data leaked to JSON causing UI errors and N/A stats.
- We needed reliability without changing UI/contract, so we adopted the Kairos v4 pattern: adapter-normalized in‚Äëmemory results, minimally hardened scraper, and stats computed from a full numeric price series.

### What changed (surgical edits)
- List pages: kept primary class selectors; always ran one attribute/URL fallback; merged candidates per page; deduped by SKU; breadth‚Äëonly mini‚Äëcrawl with `SCRAPER_MAX_PAGES` (default 10); early stop on requested count.
- Pagination fix: removed `num` shadowing when parsing `?page=` so requested count is honored.
- Detail pages: retained primaries; added one attribute/text fallback per field (price, sqm, beds, baths); added SKU‚Äëfrom‚ÄëURL fallback; jitter 0.3‚Äì0.8s; timeout 15s.
- Normalization adapter: mapped to canonical fields; sanitized NaN to JSON‚Äësafe values; removed `raw_data`; coordinates None when missing; capped response properties (now 100) while keeping full price series for stats.
- API orchestration: single‚Äëflight lock; prefer in‚Äëmemory adapter results; compute stats from series; logs success/empty with optional pages_scanned (no PII); CSV retained for diagnostics.

### Outcomes observed
- Metro Manila condo run: site exposed 2 pages; crawler collected ~31 unique links; after fallbacks and SKU fixes, up to 31 normalized properties returned; UI unchanged; logs clean.
- Raising response cap beyond discovered links does not increase results unless the site exposes more pages; scraper scans 1..min(detected_pages, MAX_PAGES).

### Guardrails respected
- No new deps/headless/proxies/queues/routes; same‚Äëhost; no depth > 1.
- Secure inputs; PII‚Äëfree logging; small typed adapter module; CSV diagnostics preserved; API/UI contract unchanged.

### Quick runbook (dev)
- Backend: `pkill -f "python3 app.py" || true` then `cd backend && SCRAPER_MAX_PAGES=10 PORT=3000 python3 app.py`
- Frontend: `cd Kairos && npm run dev -- --port 3001`
- API test: `curl -s -X POST http://localhost:3000/api/cma -H "Content-Type: application/json" -d '{"psgc_province_code":"1376","property_type":"condo","count":50}' | jq`

---

## üéØ ORIGINAL PROPOSAL (What We Avoided)

### **The Initial Vision**

Build a "Planning Subsystem" as the FIRST subsystem for Kairos that:

- **Technology:** Python + GLM-4.5-AIR (Chinese AI model)
- **Architecture:** 5 subsystems (Planning, Perception, Memory, Execution, Verification)
- **Approach:** AI-powered brain that reasons about data collection BEFORE scraping
- **Features:**
  - Predicts data quality before scraping
  - Creates intelligent scraping strategies
  - Applies "Claude-style critical reasoning"
  - Philippine market intelligence (monsoon adjustments, OFW remittances, etc.)
  - Confidence scoring and fallback strategies

### **Proposed Timeline**

```
Week 1-4:   Build Planning Subsystem (Python + GLM-4.5-AIR)
Week 5-8:   Build scrapers to receive planning strategies
Week 9-12:  Integrate everything together
Week 13+:   Finally ship to users

Total: 3-4 months to first demo
```

### **Proposed Costs**

- **Per Report:** $2.50 (5 GLM-4.5-AIR API calls)
- **Hosting:** $19/month (Netlify Pro for Background Functions)
- **At 100 reports/month:** $269/month

### **Proposed Complexity**

- Two languages (TypeScript frontend + Python backend)
- Five subsystems with complex interactions
- AI integration and prompt engineering
- Agent architecture with state management
- Privacy concerns (user data to Chinese AI)

---

## üîç CRITICAL ANALYSIS (Why It Was Wrong)

### **Fatal Flaw #1: Building Brain Before Body**

**The Problem:**
Creating a planning system for scrapers that don't exist yet.

**Like:**
- Designing traffic control before building roads
- Installing smart home system before building house
- Planning telescope observations before building telescope

**Why It Fails:**
Can't intelligently plan data collection without seeing what real data looks like.

---

### **Fatal Flaw #2: Wrong Build Order**

**Proposed Order:**
```
1. Planning Subsystem (AI reasoning)
2. Build scrapers (to receive strategies)
3. Collect data
4. Generate reports
```

**Correct Order:**
```
1. Build scrapers (get real data)
2. Generate reports (prove value exists)
3. Learn from users (what do they need?)
4. THEN add intelligence (if validated)
```

**Principle:** Build foundation first, optimization layer last.

---

### **Fatal Flaw #3: AI Where Logic Suffices**

**Most "subsystems" didn't need AI:**

| Subsystem | Proposed (AI) | Reality (Logic) |
|-----------|---------------|-----------------|
| **Planning** | GLM decides scraper priority | `if (location === 'NCR') use Lamudi else use Facebook` |
| **Memory** | GLM stores patterns | Supabase database tables |
| **Perception** | GLM normalizes addresses | ph-address library |
| **Execution** | GLM orchestrates | `Promise.allSettled([scraper1, scraper2])` |
| **Verification** | GLM detects outliers | `Math.abs(price - avg) > 2 * stdDev` |

**Only report narrative generation needs AI.**

**Cost comparison:**
- AI approach: $2.50 per report
- Logic approach: $0 per report

---

### **Fatal Flaw #4: Premature Optimization**

**The Lean Startup Principle:**
Build ‚Üí Measure ‚Üí Learn ‚Üí Iterate

**What was proposed:**
Build Perfect System ‚Üí Hope Users Want It

**Problems:**
- 3 months before first user feedback
- Can't pivot easily (too much invested)
- Don't know if users value "intelligence"
- Sunk cost fallacy (can't abandon after 3 months work)

---

### **Fatal Flaw #5: Hard-Coded "Intelligence"**

**Example from proposal:**
```python
if 6 <= current_month <= 10:
    velocity_multiplier *= 0.85  # Monsoon season
if current_month == 12:
    velocity_multiplier *= 1.25  # OFW remittances
```

**Problems:**
- Climate patterns shifting (not fixed June-Oct anymore)
- Market dynamics evolve (post-pandemic changes)
- No validation (where's data proving 0.85 is correct?)
- Regional differences (Cebu ‚â† Manila)
- Maintenance burden (update code when market changes)

**Should be:** Data-driven from historical analysis, not assumption-driven.

---

## üí° PIVOT #1: Remove AI Entirely (Week 1)

### **The Realization**

"Why spend 3 months building AI reasoning before validating anyone wants CMA reports?"

### **The Decision**

**Remove GLM-4.5-AIR completely from MVP.**

Add as "complementary feature" only AFTER:
- Users prove they want basic reports
- Users request AI-written narratives
- Have revenue to justify AI costs

### **Impact**

- ‚úÖ Saved 4+ weeks of AI integration
- ‚úÖ Saved $2.50 per report
- ‚úÖ No privacy concerns
- ‚úÖ Simpler codebase
- ‚úÖ Faster to ship

### **What Was Kept**

Simple calculations:
- Average price: `sum(prices) / count`
- Median price: `sorted(prices)[middle]`
- Range: `[min, max]`
- Count: `properties.length`

No AI needed for this.

---

## üèóÔ∏è PIVOT #2: Serverless Won't Work (Week 1)

### **The Discovery**

"Can I just use Netlify Functions instead of a VPS?"

### **The Research**

| Platform | Max Execution Time | Your Scraper Needs |
|----------|-------------------|-------------------|
| **Netlify Free** | 10 seconds | 5-10 MINUTES ‚ùå |
| **Netlify Pro** | 26 seconds | 5-10 MINUTES ‚ùå |
| **Vercel Free** | 10 seconds | 5-10 MINUTES ‚ùå |
| **Vercel Pro** | 60 seconds | 5-10 MINUTES ‚ùå |
| **Render Free** | No limit | 5-10 MINUTES ‚úÖ |

### **The Reality**

Serverless platforms CANNOT run 5-10 minute web scrapers. This is a physics problem, not a configuration problem.

### **Impact**

- ‚ùå Cannot use Netlify Functions
- ‚ùå Cannot use Vercel Serverless
- ‚úÖ Need actual server (VPS or long-running service)

---

## üéØ PIVOT #3: Render + UptimeRobot = Free (Week 1)

### **The Problem**

Render free tier spins down after 15 minutes of inactivity.

First request after sleep:
- Wake up: 1 minute
- Scrape: 5-10 minutes
- **Total: 6-11 minutes** (terrible UX)

### **Your Solution**

"I can use UptimeRobot to ping every 5 minutes. I've done this before on another project."

### **Why This Works**

**UptimeRobot (free):**
- Pings `/health` endpoint every 5 minutes
- Keeps Render server awake
- Prevents spin-down delay

**Result:** Effectively unlimited uptime for $0.

### **Impact**

- ‚úÖ Render free tier usable
- ‚úÖ No spin-down delays
- ‚úÖ Total cost: $0

**This was brilliant.** You already had proven solution.

---

## üîÑ PIVOT #4: One Platform, Not Two (Week 2)

### **Initial Recommendation**

- Frontend: Netlify (already working)
- Backend: Render (new)
- Total: 2 platforms

**Reasoning:** Don't touch what's working (risk-averse).

### **Your Question**

"Why maintain TWO platforms? Can't I just use Render for everything?"

### **Your Logic**

- Already adding Render for backend
- Render can host static sites too
- One platform = simpler
- One config file (render.yaml)
- One dashboard
- One deployment

### **The Decision**

**You were right.** One platform IS simpler.

Move everything to Render:
- Static Site (frontend)
- Web Service (backend)
- Single render.yaml deploys both

### **Impact**

- ‚úÖ One platform to learn
- ‚úÖ One configuration file
- ‚úÖ One deployment process
- ‚úÖ Simpler mental model
- ‚úÖ Easier to manage

**Lesson:** I was optimizing for risk-aversion. You were optimizing for simplicity. For MVP, simplicity wins.

---

## üêç PIVOT #5: It's Python, Not Node.js (Week 2)

### **The Discovery**

You shared: https://github.com/njolnir/Lamudi_Scraper

### **The Shock**

**I had assumed:** Node.js scraper (because frontend is TypeScript)
**Reality:** Python scraper (BeautifulSoup, pandas)

### **Impact**

**All my code examples were wrong language.**

Had to revise entire implementation:
- ‚ùå Express server ‚Üí ‚úÖ Flask server
- ‚ùå npm packages ‚Üí ‚úÖ pip packages
- ‚ùå JavaScript scraper integration ‚Üí ‚úÖ Python function calls
- ‚ùå Node.js deployment ‚Üí ‚úÖ Python runtime

### **New Stack**

```
Frontend: React/TypeScript (unchanged)
Backend: Python/Flask (changed from Node.js)
Scraper: Python (BeautifulSoup)
Platform: Render (supports both)
```

### **Lesson**

Always verify tech stack assumptions before proposing architecture.

---

## üìä OLD VS NEW COMPARISON

### **ORIGINAL APPROACH (Avoided)**

```
Technology:
‚îú‚îÄ Python backend
‚îú‚îÄ GLM-4.5-AIR (Chinese AI)
‚îú‚îÄ 5 subsystems (agent architecture)
‚îú‚îÄ Philippine market intelligence (hard-coded)
‚îî‚îÄ Complex state management

Timeline:
‚îú‚îÄ Week 1-4:   Planning Subsystem
‚îú‚îÄ Week 5-8:   Build scrapers
‚îú‚îÄ Week 9-12:  Integration
‚îî‚îÄ Week 13+:   Ship to users

Cost:
‚îú‚îÄ Per report: $2.50 (5 AI calls)
‚îú‚îÄ Hosting: $19/month (Netlify Pro)
‚îî‚îÄ At 100 reports: $269/month

Complexity:
‚îú‚îÄ Two languages (TypeScript + Python)
‚îú‚îÄ AI integration (prompts, error handling)
‚îú‚îÄ Agent architecture (subsystem coordination)
‚îú‚îÄ Privacy concerns (Chinese AI)
‚îî‚îÄ Hard to maintain

Risk:
‚îú‚îÄ Build for 3 months before user feedback
‚îú‚îÄ Might be building wrong thing
‚îú‚îÄ High sunk cost (can't abandon easily)
‚îî‚îÄ Expensive to run at scale
```

---

### **NEW LEAN APPROACH (What We Built)**

```
Technology:
‚îú‚îÄ Python/Flask backend (minimal)
‚îú‚îÄ Open-source scraper (existing)
‚îú‚îÄ Simple REST API (one endpoint)
‚îú‚îÄ Basic math (average, median, range)
‚îî‚îÄ No AI (just calculations)

Timeline:
‚îú‚îÄ Week 1:  Scraper + Flask wrapper
‚îú‚îÄ Week 2:  Deploy + Connect frontend
‚îî‚îÄ Week 3:  Polish + Demo prep

Cost:
‚îú‚îÄ Per report: $0
‚îú‚îÄ Hosting: $0 (Render free tier)
‚îú‚îÄ Monitoring: $0 (UptimeRobot free)
‚îî‚îÄ Total: $0

Complexity:
‚îú‚îÄ 7 files total
‚îú‚îÄ ~100 lines of new code
‚îú‚îÄ One platform (Render)
‚îú‚îÄ Standard tech (Flask + React)
‚îî‚îÄ Easy to understand

Risk:
‚îú‚îÄ Ship in 3 weeks (fast feedback)
‚îú‚îÄ Validates concept quickly
‚îú‚îÄ Low sunk cost (can pivot easily)
‚îî‚îÄ Free to run
```

---

## üéì KEY INSIGHTS

### **Insight #1: AI ‚â† Intelligence**

**Misconception:** "AI makes systems intelligent"

**Reality:** Most intelligence is just logic:
- Planning = Lookup tables
- Verification = Math formulas
- Memory = Database queries
- Perception = Library calls

**AI only valuable for:** Natural language generation, complex pattern recognition

**When to add AI:** After validating users want it and will pay for it.

---

### **Insight #2: Foundation Before Optimization**

**Wrong order:**
```
Optimization (Planning AI) ‚Üí Foundation (Scrapers) ‚Üí Product
```

**Right order:**
```
Foundation (Scrapers) ‚Üí Product ‚Üí Optimization (if needed)
```

**Why:** Can't optimize what doesn't exist. Build it first, measure it, THEN optimize bottlenecks.

---

### **Insight #3: Validate Before You Build**

**Product Development Anti-Pattern:**
```
Assume what users want
  ‚Üì
Build sophisticated solution
  ‚Üì
Hope users want it
  ‚Üì
Discover they wanted something else
  ‚Üì
Sunk cost fallacy
```

**Lean Startup Pattern:**
```
Build minimum viable version
  ‚Üì
Ship to real users
  ‚Üì
Learn what they actually want
  ‚Üì
Build THAT
  ‚Üì
Avoid waste
```

---

### **Insight #4: Simplicity Beats Sophistication**

**For 3-week MVP:**
- Simple beats sophisticated
- Fast beats perfect
- Learning beats planning
- Cheap beats expensive
- Working beats elegant

**After product-market fit:**
- Then add sophistication
- Then optimize performance
- Then build for scale
- Then invest in infrastructure

---

### **Insight #5: User Was Often Right**

**Times user corrected me:**

1. **"Why not just use Render for everything?"**
   - I said: Keep Netlify + Add Render
   - User said: Just Render
   - **User was right** ‚úÖ

2. **"I have solution for Render spin-down"**
   - I was researching paid solutions
   - User said: UptimeRobot (already proven)
   - **User was right** ‚úÖ

3. **"Why not replace netlify.toml with render.yaml?"**
   - I said: Keep both during transition
   - User said: Just use one platform
   - **User was right** ‚úÖ

**Pattern:** I optimized for risk-aversion. User optimized for simplicity. For MVP, **simplicity wins**.

---

## üìã FINAL IMPLEMENTATION PLAN

### **The Actual Steps (After All Pivots)**

1. **Test scraper locally** (15 min) - Verify it returns data
2. **Create backend folder** (10 min) - Organize code
3. **Wrap scraper in Flask** (30 min) - One endpoint
4. **Add dependencies** (2 min) - requirements.txt
5. **Test locally** (10 min) - curl the API
6. **Create render.yaml** (5 min) - Deploy config
7. **Deploy to Render** (10 min) - Git push
8. **Set up UptimeRobot** (5 min) - Keep awake
9. **Call API from frontend** (20 min) - Add function
10. **Deploy frontend** (5 min) - Git push
11. **Test end-to-end** (30 min) - Full verification

**Total time:** ~4 hours  
**Total files:** 3 new, 1 modified  
**Total code:** ~100 lines

---

## üí∞ COST COMPARISON

| Item | Original | Final | Savings |
|------|----------|-------|---------|
| **AI per report** | $2.50 | $0 | $2.50 |
| **Hosting** | $19/month | $0 | $19/month |
| **Monitoring** | - | $0 | - |
| **At 100 reports** | $269/month | $0 | $269/month |
| **At 1000 reports** | $2,519/month | $0 | $2,519/month |

**Total savings over 6 months (at 100 reports/month): $1,614**

---

## ‚è∞ TIME COMPARISON

| Milestone | Original | Final | Time Saved |
|-----------|----------|-------|------------|
| **Backend working** | Week 4-8 | Week 1 | 3-7 weeks |
| **First deployment** | Week 9-12 | Week 2 | 7-10 weeks |
| **Demo ready** | Month 4+ | Week 3 | 2-3 months |
| **User feedback** | Month 4+ | Week 3 | 2-3 months |

**Total time saved: 2-3 months**

---

## üéØ WHAT WE'RE ACTUALLY BUILDING

### **Product**
Kairos - Philippine Real Estate CMA Tool

### **Target**
3 companies in 3 weeks (demo deadline)

### **Tech Stack**
```
Frontend:
‚îú‚îÄ React/TypeScript
‚îú‚îÄ Vite build system
‚îú‚îÄ Deployed: Render Static Site
‚îî‚îÄ Cost: $0

Backend:
‚îú‚îÄ Python/Flask
‚îú‚îÄ Open-source Lamudi scraper
‚îú‚îÄ Deployed: Render Web Service
‚îî‚îÄ Cost: $0

Monitoring:
‚îú‚îÄ UptimeRobot (keeps backend awake)
‚îî‚îÄ Cost: $0

Total Infrastructure: $0/month
```

### **Features (MVP)**
‚úÖ Enter Philippine address  
‚úÖ Filter by property type  
‚úÖ Scrape real Lamudi data (5-10 min)  
‚úÖ Calculate statistics (avg, median, range)  
‚úÖ Display results in UI  
‚úÖ Basic error handling

### **NOT Included (Add Later)**
‚ùå Multiple scrapers (just Lamudi for now)  
‚ùå Database/report history  
‚ùå User accounts  
‚ùå AI-generated narratives  
‚ùå Advanced analytics  
‚ùå PDF export  
‚ùå Historical trends

**Philosophy:** Ship minimal ‚Üí Learn ‚Üí Add what users actually want

---

## üîÆ WHAT HAPPENS NEXT

### **If Demos Succeed (Companies Want to Buy)**

**Immediate additions:**
- User authentication (Supabase Auth)
- Save reports (Supabase Database)
- Payment processing (Stripe)
- More scrapers (Carousell, Facebook)
- PDF export

**Architecture impact:**
- Current structure supports all this
- Add new Flask endpoints
- Add new React components
- Scale Render to paid tier (~$20/month)

**Cost with revenue:**
- $20/month hosting is affordable
- Can add AI narratives ($0.50 per report via Claude)
- ROI positive if charging $10-20 per report

---

### **If Demos Fail (Companies Don't Want This)**

**Questions to answer:**
- Why didn't they want it?
- Too slow? Wrong data? Wrong features?
- Different target market?

**Time wasted:**
- Only 3 weeks
- Only $0 spent
- Only ~100 lines of code

**Pivot options:**
- Try different market segment
- Try different data source
- Try different product with same tech
- Learn and move on

**Key advantage:** Low sunk cost makes pivoting easy.

---

## üìö LESSONS FOR FUTURE PROJECTS

### **Do:**
‚úÖ Start with simplest possible version  
‚úÖ Validate with real users fast  
‚úÖ Use free tools when possible  
‚úÖ Keep codebase lean  
‚úÖ Question complexity  
‚úÖ Trust your instincts  
‚úÖ One platform when possible

### **Don't:**
‚ùå Build sophisticated features before validation  
‚ùå Add AI when logic suffices  
‚ùå Over-engineer for imaginary scale  
‚ùå Plan extensively without executing  
‚ùå Ignore simpler alternatives  
‚ùå Maintain multiple platforms unnecessarily  
‚ùå Build for months without user feedback

### **Remember:**
> "Perfect is the enemy of good"  
> "Make it work, make it right, make it fast" (in that order)  
> "Build the telescope before planning which stars to observe"

---

## üöÄ NEXT ACTION

**Start here:**
```bash
git clone https://github.com/njolnir/Lamudi_Scraper.git
cd Lamudi_Scraper
pip install -r requirements.txt
python lamudi_scraper.py
```

**If scraper works:** Follow 11-step implementation plan  
**If scraper broken:** Debug it together first

**3 weeks from now:** Demo to 3 companies with working product

---

## üîÑ PIVOT #6: Component Data Sources - Scraped vs Projected (October 2025)

### **The Problem**

After integrating ML projections CSV into the dashboard, **all components appeared static** when searching different locations within the same province. Users perceived the entire dashboard as unchanging, even though ML projections were updating correctly in the background.

### **The Discovery**

**Root Cause:** Multiple data sources were mixed together in components, creating confusion:
- Scraped data (real Lamudi listings) naturally shows the same results for locations within the same province
- ML projections were changing dynamically, but users couldn't see the difference
- Components showed a mix of both, making it unclear what was real vs projected

### **The Decision**

**Isolate data sources at the component level:**

#### **Scraped Data Only (Real Lamudi Results):**
1. ‚úÖ **Property Report** - Real property listings from Lamudi
2. ‚úÖ **CMA Summary** (Average, Median, Range) - Calculated from scraped properties
3. ‚úÖ **Locations/Neighborhoods** - Real neighborhood data from listings

#### **ML Projections Only (CSV-Driven):**
1. ‚úÖ **Avg Days on Market** (MetricCard) - From `projection.avg_dom`
2. ‚úÖ **Market Activity** (Active/Pending/Closed) - From `projection.active_count`, `pending_count`, `closed_count`
3. ‚úÖ **Avg Sold Price** (CMASummaryTable) - From `projection.avg_sold_price`
4. ‚úÖ **Median Sold Price** (CMASummaryTable) - From `projection.median_sold_price`
5. ‚úÖ **Avg Days on Market** (LocationsTable) - From `projection.avg_dom`
6. ‚úÖ **Historical Trends** - From `projection.trend_6m` (6-month price trajectory)

### **Why This Works**

**Clear Data Boundaries:**
- Users understand which metrics are from real listings (Property Report, CMA)
- Which metrics are market intelligence projections (DOM, Market Activity, Historical Trends)
- No confusion about data sources

**Dynamic Updates:**
- When searching "Metro Manila" ‚Üí Shows Metro Manila projections
- When searching "Cebu" ‚Üí Shows Cebu projections
- Each of the 18 locations has unique ML projections

**Professional Transparency:**
- Projected data labeled as "Market Intelligence (X data points)"
- Mock data labels removed from real scraped components
- Users trust what they see because sources are clear

### **Implementation Changes**

**CSV Loading & State Management:**
```typescript
// App.tsx
const [projectionsMap, setProjectionsMap] = useState<Map<string, ProjectionData>>(new Map());
const [currentProjection, setCurrentProjection] = useState<ProjectionData | null>(null);

// Load CSV on mount
useEffect(() => {
  loadProjections().then(setProjectionsMap);
}, []);

// Update projection when address changes
useEffect(() => {
  if (selectedAddress?.location?.psgc_province_code) {
    const psgcCode = selectedAddress.location.psgc_province_code.toString();
    let projection = projectionsMap.get(psgcCode);
    
    // Fallback to name-based matching if PSGC fails
    if (!projection && selectedAddress.full_address) {
      projection = findProjectionByName(projectionsMap, selectedAddress.full_address);
    }
    
    setCurrentProjection(projection || null);
  }
}, [selectedAddress, projectionsMap]);
```

**Component Prop Drilling:**
```typescript
// Pass projections only to components that need them
<MetricCard 
  title="Avg Days on Market" 
  value={currentProjection ? `${currentProjection.avg_dom}` : "28"} 
/>

<MarketActivity cma={cma} projection={currentProjection} />
<HistoricalTrends cma={cma} projection={currentProjection} />
<CMASummaryTable cma={cma} projection={currentProjection} />
<LocationsTable cma={cma} projection={currentProjection} />
```

**Component Updates:**
```typescript
// MarketActivity.tsx - Use projections directly
const activeCount = projection ? projection.active_count : Math.floor(totalCount * 0.68);
const pendingCount = projection ? projection.pending_count : Math.floor(totalCount * 0.25);
const closedCount = projection ? projection.closed_count : Math.floor(totalCount * 0.07);

// HistoricalTrends.tsx - Use 6-month trend data
const dataPoints = projection?.trend_6m || [450, 465, 470, 472, 478, 485];
```

### **Impact**

**Before Pivot:**
- ‚ùå Users confused about static vs dynamic data
- ‚ùå Mock data labels everywhere ("Mock data placeholder")
- ‚ùå Mixed data sources in components
- ‚ùå Unclear what's real vs projected

**After Pivot:**
- ‚úÖ Clear separation: Real listings vs Market intelligence
- ‚úÖ Dynamic projections for 18 Philippine locations
- ‚úÖ Professional labeling ("Market Intelligence (X data points)")
- ‚úÖ Users trust the dashboard because sources are transparent

### **Technical Details**

**CSV Structure:**
```csv
psgc_code,area_name,avg_sold_price,median_sold_price,avg_dom,active_count,pending_count,closed_count,trend_6m,confidence,sample_size
1376,Metro Manila,16631289,15325748,38,50,18,5,"16225648,16808081,16923067,17363097,17634040,16631289",high,4148
```

**Projection Lookup Logic:**
1. **PSGC Code Match** - Exact match on province code
2. **Name-Based Fallback** - Case-insensitive partial matching
3. **Graceful Degradation** - Falls back to reasonable defaults if no projection found

**Coverage:**
- 18 Philippine locations with ML projections
- Realistic market fluctuations (seasonal trends, volatility)
- Confidence levels: High (4000+ samples) to Low (10-50 samples)

### **UI/UX Improvements**

**Removed Distracting Elements:**
- ‚ùå Removed green percentage texts ("+12% from last month", "N/A")
- ‚ùå Removed "View" links from individual property listings
- ‚ùå Removed red "Mock data placeholder" labels from scraped components
- ‚úÖ Kept only Historical Trends visualization for trend display

**Label Updates:**
- Changed red text ‚Üí gray text for softer appearance
- "Mock data placeholder" ‚Üí "Market Intelligence (X data points)"
- Maintained transparency about projection sources

### **Guardrails Respected**

‚úÖ **Minimal Technical Debt** - Just CSV parsing, no new libraries  
‚úÖ **No Backend Changes** - Frontend-only integration  
‚úÖ **Type Safety** - Full TypeScript interfaces (`ProjectionData`)  
‚úÖ **Scalable** - Easy to update CSV monthly with new ML runs  
‚úÖ **Transparent** - Clear labeling of data sources  
‚úÖ **Simple** - ~100 lines of new code, 1 new file

### **Lessons Learned**

1. **Data Source Clarity > Feature Richness** - Users need to trust what they see
2. **Component Isolation** - Each component should have a clear, singular data source
3. **Transparent Labeling** - Always show users where data comes from
4. **Graceful Fallbacks** - Name-based matching improves UX when PSGC codes mismatch
5. **CSV is Sufficient** - No need for database/API for static projections

### **Future Enhancements**

**When ML model improves:**
- Just replace `projections.csv` with updated file
- No code changes needed
- Projections update automatically

**When adding more locations:**
- Add rows to CSV
- Lookup logic already handles new entries
- No component changes required

**When integrating real MLS data:**
- Replace ML projections with actual temporal data
- Same component structure works
- Just swap data source

---

## üìù DOCUMENT METADATA

**Created:** September 30, 2025  
**Author:** Sean Macalintal (with AI assistance)  
**Purpose:** Record architectural pivots and decision rationale  
**Status:** Active reference document  
**Last Updated:** October 9, 2025

**Related Documents:**
- `PSGC-DATA-SEARCHING-REFERENCE.md` - Address search architecture decisions
- `KAIROS-DASHBOARD-DESIGN-SYSTEM.md` - ML Projections Integration details
- `Kairos/README.md` - Project overview
- `render.yaml` - Deployment configuration

---

**END OF DOCUMENT**
